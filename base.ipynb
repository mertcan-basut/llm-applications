{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZb6JDxIq9ypQQ/MJL51j+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertcan-basut/llm-applications/blob/main/base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "K8vLXIu5i9lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract Base Class"
      ],
      "metadata": {
        "id": "KSgoWcJ_cZUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "BFp8Lobig48e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Message:\n",
        "    def __init__(self, role, content):\n",
        "        self.role = role\n",
        "        if content is None or content.strip() == \"\":\n",
        "            raise ValueError(\"Content cannot be empty\")\n",
        "        self.content = content\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_template(cls, role, template, **params):\n",
        "        content = template.format(**params)\n",
        "        return cls(role=role, content=content)"
      ],
      "metadata": {
        "id": "ALriEGm821EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMBase(ABC):\n",
        "    def __init__(self, model_name, **params):\n",
        "        self.model_name = model_name\n",
        "        self.params = params\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _construct_prompt(self, message):\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_completion(self, client, model_name, messages **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_params(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_usage_metadata(self, completion):\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_output(self, messages, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_structured_output(self, messages, output_schema, **kwargs):\n",
        "        pass"
      ],
      "metadata": {
        "id": "9ngLkAAUcO7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concrete Class"
      ],
      "metadata": {
        "id": "ZkI0zDvDcgLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "QTa9FqRxNBpI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "aOeTEKa4h0oc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleLLM(LLMBase):\n",
        "    def __init__(self, api_key, model_name, **params):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel()\n",
        "\n",
        "        super().__init__(model_name=model_name, **params)\n",
        "\n",
        "\n",
        "    def _construct_prompt(self, message):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def _get_completion(self, client, model_name, messages **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def _get_params(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def _get_usage_metadata(self, completion):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def get_output(self, messages, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def get_structured_output(self, messages, output_schema, **kwargs):\n",
        "        pass"
      ],
      "metadata": {
        "id": "Bvbz99tIhp-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Factory Class"
      ],
      "metadata": {
        "id": "dqa_zPXQim5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLM:\n",
        "    def __init__(self, provider, api_key, model_name, **kwargs):\n",
        "        if provider == \"google\":\n",
        "            self.llm = GoogleLLM(api_key=api_key, model_name=model_name, **kwargs)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown provider: {provider}\")\n",
        "\n",
        "\n",
        "    def get_output(self, messages, **kwargs):\n",
        "        output, usage_metadata = self.llm.get_output(messages, **kwargs)\n",
        "        return output, usage_metadata\n",
        "\n",
        "\n",
        "    def get_structured_output(self, messages, output_schema, **kwargs):\n",
        "        output, usage_metadata = self.llm.get_structured_output(messages, output_schema, **kwargs)\n",
        "        return output, usage_metadata"
      ],
      "metadata": {
        "id": "vJUGQRgpioYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {
        "id": "Zf02TpotjErI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "AU0vAF08uU3u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(\n",
        "    provider='google',\n",
        "    api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "    model_name='gemini-1.5-flash-002'\n",
        ")"
      ],
      "metadata": {
        "id": "5dB33k4-jFqR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}